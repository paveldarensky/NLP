# -*- coding: utf-8 -*-
"""NLP_LW1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LHnUqlgs7KBuO83nj85tCdRdeHaJkXUd
"""

# устанавливаем pymorphy3
# !pip install pymorphy3 --q

# подключаем необходимые библиотеки
import nltk
from nltk.tokenize import word_tokenize, sent_tokenize

import pymorphy3

nltk.download("punkt") # Загружает в систему данные для токенизатора предложений и слов
nltk.download("punkt_tab") # Это дополнение к punkt, которое появилось в новых версиях NLTK (без него выдает ошибку).
morph = pymorphy3.MorphAnalyzer() # объект морфологического анализатора

# читаем текст
path = 'text.txt'
with open(path, "r", encoding="utf-8") as f:
    text = f.read()

# проверим содержимое
print(text)

sentences = sent_tokenize(text, language="russian")
print("Предложения:")
for s in sentences:
    print("-", s)

# Оставляем только слова (без пунктуации, чисел и т.п.)
# isalpha() - проверяет, что строка содержит только буквы
tokens_all = []
for sent in sentences:
    tokens = word_tokenize(sent, language="russian")
    tokens = [t for t in tokens if t.isalpha()]   # только слова
    tokens_all.extend(tokens)

print("\nВсе токены:")
print(tokens_all)

# Лемматизация и получение грамматических атрибутов
parsed = [morph.parse(t)[0] for t in tokens_all]

pairs = []

# проход по соседним словам
for i in range(len(parsed) - 1):
    w1 = parsed[i]
    w2 = parsed[i+1]

    # Проверка частей речи: хотя бы одно NOUN или ADJ(F/S) (полное прил / краткое прил)
    if not (("NOUN" in w1.tag or "ADJF" in w1.tag or "ADJS" in w1.tag) or
     ("NOUN" in w2.tag or "ADJF" in w2.tag or "ADJS" in w2.tag)):
     continue

    # Извлекаем род, число и падеж
    g1 = {w1.tag.gender, w1.tag.number, w1.tag.case}
    g2 = {w2.tag.gender, w2.tag.number, w2.tag.case}

    # Совпадение по роду, числу и падежу
    if w1.tag.gender == w2.tag.gender and \
       w1.tag.number == w2.tag.number and \
       w1.tag.case == w2.tag.case:
        pairs.append((w1.normal_form, w2.normal_form))

# результат
for p in pairs:
    print(p)

# проверка всех слов текста на грамматические атрибуты
for p in parsed:
    print(
        f"{p.word:<12} → {p.normal_form:<10} | {p.tag.POS:<5} | "
        f"род={p.tag.gender}, число={p.tag.number}, падеж={p.tag.case}"
    )

