# -*- coding: utf-8 -*-
"""NLP_LW3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rlgi0P_PuxMff6OnzSIXZ6zTWDm-ssi3
"""

# Установка необходимых библиотек
# !pip install tensorflow
# !pip install torch
# !pip install transformers

# Подключение необходимых библиотек
from transformers import BertTokenizer, BertForMaskedLM # BertTokenizer — для разбиения текста на токены, которые понимает BERT, BertForMaskedLM — сама модель BERT для задачи предсказания пропущенного слова
from torch.nn import functional as F # функциональные операции PyTorch (для softmax)
import torch # библиотека PyTorch

# Моя пара слов для выполнения задания: "хорошо" и "всегда".

name = "bert-base-multilingual-uncased" # мультиязычная BERT
tokenizer = BertTokenizer.from_pretrained(name) # загружаем токенизатор
model = BertForMaskedLM.from_pretrained(name, return_dict = True) # загружаем веса модели для MLM, return_dict=True — модель возвращает словарь с логитами

text = "Я " + tokenizer.mask_token + " помню правила дорожного движения и соблюдаю их." # Задаём предложение с пропущенным словом
input = tokenizer.encode_plus(text, return_tensors = "pt") # Преобразуем текст в идентификаторы токенов (input_ids) для модели, return_tensors="pt" — возвращает PyTorch тензор
mask_index = torch.where(input["input_ids"][0] == tokenizer.mask_token_id) # Находим позицию [MASK] в последовательности токенов, tokenizer.mask_token_id — числовой ID для [MASK]
output = model(**input) # Передаём токены в модель BERT

logits = output.logits # Модель возвращает logits — числовые оценки (выход нейросети до применения функции вероятностей) для вероятности каждого токена на каждом месте
softmax = F.softmax(logits, dim = -1) # Применяем softmax, чтобы получить вероятности слов на каждой позиции, dim=-1 — считаем softmax по всем токенам словаря
mask_word = softmax[0, mask_index[0], :] # Берём вероятности только для позиции [MASK], получаем вектор длиной vocab_size, где каждый элемент = вероятность токена на этом месте
top = torch.topk(mask_word, 10) # возвращает топ-10 слов с наибольшей вероятностью
for token in top[-1][0].data:
  print(tokenizer.decode([token])) # Переводим числовые ID обратно в слова
# не, хорошо, всегда, также, часто, просто, только, постоянно, сам, здесь